{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 폴더만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import os\n",
    "\n",
    "win = Tk() # 창 생성\n",
    "\n",
    "ent = Entry(win) # 입력창 생성\n",
    "\n",
    "def ent_p():\n",
    "    a = ent.get()\n",
    "\n",
    "    parent_dir = \"train\"\n",
    "\n",
    "    path = os.path.join(parent_dir, a)\n",
    "\n",
    "    os.makedirs(path)\n",
    "\n",
    "ent.pack() # 입력창 배치\n",
    "\n",
    "btn = Button(win)\n",
    "btn.config(text = \"신원등록\")\n",
    "btn.config(command = ent_p)\n",
    "btn.pack()\n",
    " \n",
    "win.mainloop() # 창 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사진촬영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image # Pillow\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# GUI 설계\n",
    "win = Tk() # 인스턴스 생성\n",
    "\n",
    "win.title(\"신원확인 시스템\") # 제목 표시줄 추가\n",
    "win.option_add(\"*Font\", \"맑은고딕 25\") # 전체 폰트\n",
    "\n",
    "# 라벨 추가\n",
    "lbl = Label(win, text=\"신원확인 시스템\")\n",
    "lbl.grid(row=0, column=0) # 라벨 행, 열 배치\n",
    "\n",
    "# 프레임 추가\n",
    "frm = Frame(win, bg=\"white\", width=720, height=480) # 프레임 너비, 높이 설정\n",
    "frm.grid(row=1, column=0) # 격자 행, 열 배치\n",
    "\n",
    "# 라벨 추가\n",
    "lbl1 = Label(frm)\n",
    "lbl1.grid()\n",
    "\n",
    "cap = cv2.VideoCapture(0) # VideoCapture 객체 정의\n",
    "\n",
    "def video_play():\n",
    "   ret, frame = cap.read()\n",
    "   frame = cv2.flip(frame, 1) # 상하반전\n",
    "   frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "   img = Image.fromarray(frame)\n",
    "   imgtk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "   lbl1.imgtk = imgtk\n",
    "   lbl1.configure(image=imgtk)\n",
    "   lbl1.after(10, video_play)\n",
    "\n",
    "video_play()\n",
    "\n",
    "# 버튼 추가\n",
    "btn = Button(win, text = \"촬영\") # 버튼 생성\n",
    "btn.grid(row=2, column=0) # 라벨 행, 열 배치\n",
    "btn.config(width = 5, height = 1) # 버튼 크기\n",
    "\n",
    "def alert():\n",
    "\n",
    "   ret, frame = cap.read()\n",
    "   frame = cv2.flip(frame, 1) # Flip camera vertically\n",
    "   \n",
    "   # 컬러 이미지 저장\n",
    "   vein_img = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_picture\") + '.jpg'\n",
    "   cv2.imwrite(vein_img, frame)\n",
    "\n",
    "\n",
    "btn.config(command = alert) # 버튼 기능\n",
    "\n",
    "win.mainloop() #GUI 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신원등록 사진촬영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image # Pillow\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# GUI 설계\n",
    "win = Tk() # 인스턴스 생성\n",
    "\n",
    "win.title(\"신원확인 시스템\") # 제목 표시줄 추가\n",
    "win.option_add(\"*Font\", \"맑은고딕 25\") # 전체 폰트\n",
    "\n",
    "# 라벨 추가\n",
    "lbl = Label(win, text=\"신원확인 시스템\")\n",
    "lbl.grid(row=0, column=0, columnspan = 2) # 라벨 행, 열 배치\n",
    "\n",
    "# 프레임 추가\n",
    "frm = Frame(win, bg=\"white\", width=720, height=480) # 프레임 너비, 높이 설정\n",
    "frm.grid(row=1, column=0, columnspan = 2) # 격자 행, 열 배치\n",
    "\n",
    "# 프레임 추가\n",
    "frm1 = Frame(win, width=700, height=75) # 프레임 너비, 높이 설정\n",
    "frm1.grid(row=3, column=0, columnspan = 2) # 격자 행, 열 배치\n",
    "\n",
    "# 라벨 추가\n",
    "lbl1 = Label(frm)\n",
    "lbl1.grid()\n",
    "\n",
    "cap = cv2.VideoCapture(0) # VideoCapture 객체 정의\n",
    "\n",
    "def video_play():\n",
    "   ret, frame = cap.read()\n",
    "   frame = cv2.flip(frame, 1) # 상하반전\n",
    "   frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "   img = Image.fromarray(frame)\n",
    "   imgtk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "   lbl1.imgtk = imgtk\n",
    "   lbl1.configure(image=imgtk)\n",
    "   lbl1.after(10, video_play)\n",
    "\n",
    "video_play()\n",
    "\n",
    "# 입력창 생성\n",
    "ent = Entry(win)\n",
    "ent.grid(row=2, column=0, columnspan = 2)\n",
    "ent.insert(0,\" 이름을 입력해주세요.. \") # 입력창 문자열 삽입\n",
    "\n",
    "def clear(event):\n",
    "    ent.delete(0, len(ent.get()))\n",
    "\n",
    "ent.bind(\"<Button-1>\", clear) # 입력창 클릭시 명령 (Button-1 = 좌클릭)\n",
    "\n",
    "# 버튼 추가\n",
    "btn = Button(win, text = \"신원등록\") # 버튼 생성\n",
    "btn.grid(row=3, column=0) # 라벨 행, 열 배치\n",
    "btn.config(width = 7, height = 1) # 버튼 크기\n",
    "\n",
    "# 버튼 추가\n",
    "btn1 = Button(win, text = \"촬영\") # 버튼 생성\n",
    "btn1.grid(row=3, column=1) # 라벨 행, 열 배치\n",
    "btn1.config(width = 7, height = 1) # 버튼 크기\n",
    "\n",
    "def alert():\n",
    "\n",
    "   a = ent.get()\n",
    "\n",
    "   parent_dir = \"train\"\n",
    "\n",
    "   path = os.path.join(parent_dir, a)\n",
    "\n",
    "   os.makedirs(path)\n",
    "    \n",
    "def alert1():\n",
    "\n",
    "   a = ent.get()\n",
    "\n",
    "   parent_dir = \"train\"\n",
    "\n",
    "   path = os.path.join(parent_dir, a)\n",
    "    \n",
    "   ret, frame = cap.read()\n",
    "   frame = cv2.flip(frame, 1) # Flip camera vertically\n",
    "   \n",
    "   # 컬러 이미지 저장\n",
    "   vein_img = path+ '\\picture_'+ datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.jpg'\n",
    "   cv2.imwrite(vein_img, frame)\n",
    "\n",
    "\n",
    "btn.config(command = alert) # 버튼 기능\n",
    "btn1.config(command = alert1) # 버튼 기능\n",
    "\n",
    "win.mainloop() #GUI 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN 알고리즘 신원확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n",
      "Training complete!\n",
      "Setting cameras up...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'JPG'}\n",
    "\n",
    "\n",
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through each person in the training set\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Loop through each training image for the current person\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                # If there are no people (or too many people) in a training image, skip the image.\n",
    "                if verbose:\n",
    "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                # Add face encoding for current image to the training set\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    # Create and train the KNN classifier\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf\n",
    "\n",
    "\n",
    "def predict(X_frame, knn_clf=None, model_path=None, distance_threshold=0.5):\n",
    "\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n",
    "\n",
    "    # Load a trained KNN model (if one was passed in)\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    X_face_locations = face_recognition.face_locations(X_frame)\n",
    "\n",
    "    # If no faces are found in the image, return an empty result.\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    # Find encodings for faces in the test image\n",
    "    faces_encodings = face_recognition.face_encodings(X_frame, known_face_locations=X_face_locations)\n",
    "\n",
    "    # Use the KNN model to find the best matches for the test face\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    # Predict classes and remove classifications that aren't within the threshold\n",
    "    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n",
    "\n",
    "\n",
    "def show_prediction_labels_on_image(frame, predictions):\n",
    "\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        # enlarge the predictions for the full sized image.\n",
    "        top *= 2\n",
    "        right *= 2\n",
    "        bottom *= 2\n",
    "        left *= 2\n",
    "        # Draw a box around the face using the Pillow module\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "        # There's a bug in Pillow where it blows up with non-UTF-8 text\n",
    "        # when using the default bitmap font\n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "    # Remove the drawing library from memory as per the Pillow docs.\n",
    "    del draw\n",
    "    # Save image in open-cv format to be able to show it.\n",
    "\n",
    "    opencvimage = np.array(pil_image)\n",
    "    return opencvimage\n",
    "\n",
    "\n",
    "print(\"Training KNN classifier...\")\n",
    "classifier = train(\"train\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "print(\"Training complete!\")\n",
    "# process one frame in every 30 frames for speed\n",
    "process_this_frame = 29\n",
    "print('Setting cameras up...')\n",
    "# multiple cameras can be used with the format url = 'http://username:password@camera_ip:port'\n",
    "#url = 'http://admin:admin@192.168.0.106:8081/'\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1 > 0:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Different resizing options can be chosen based on desired program runtime.\n",
    "        # Image resizing for more stable streaming\n",
    "        img = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        process_this_frame = process_this_frame + 1\n",
    "        if process_this_frame % 30 == 0:\n",
    "            predictions = predict(img, model_path=\"trained_knn_model.clf\")\n",
    "        frame = show_prediction_labels_on_image(frame, predictions)\n",
    "        cv2.imshow('camera', frame)\n",
    "            \n",
    "        key = cv2.waitKey(1)\n",
    "            \n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신원등록 사진촬영(웹캠) + KNN 알고리즘 신원확인(depth camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image, ImageDraw # Pillow\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "import os.path\n",
    "import pickle\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "from realsense_camera import *\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'JPG'}\n",
    "\n",
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through each person in the training set\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Loop through each training image for the current person\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                # If there are no people (or too many people) in a training image, skip the image.\n",
    "                if verbose:\n",
    "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                # Add face encoding for current image to the training set\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    # Create and train the KNN classifier\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf\n",
    "\n",
    "\n",
    "def predict(X_frame, knn_clf=None, model_path=None, distance_threshold=0.5):\n",
    "\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n",
    "\n",
    "    # Load a trained KNN model (if one was passed in)\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    X_face_locations = face_recognition.face_locations(X_frame)\n",
    "\n",
    "    # If no faces are found in the image, return an empty result.\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    # Find encodings for faces in the test image\n",
    "    faces_encodings = face_recognition.face_encodings(X_frame, known_face_locations=X_face_locations)\n",
    "\n",
    "    # Use the KNN model to find the best matches for the test face\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    # Predict classes and remove classifications that aren't within the threshold\n",
    "    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n",
    "\n",
    "\n",
    "def show_prediction_labels_on_image(bgr_frame, predictions):\n",
    "\n",
    "    pil_image = Image.fromarray(bgr_frame)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        # enlarge the predictions for the full sized image.\n",
    "        top *= 2\n",
    "        right *= 2\n",
    "        bottom *= 2\n",
    "        left *= 2\n",
    "        # Draw a box around the face using the Pillow module\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "        # There's a bug in Pillow where it blows up with non-UTF-8 text\n",
    "        # when using the default bitmap font\n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "    # Remove the drawing library from memory as per the Pillow docs.\n",
    "    del draw\n",
    "    # Save image in open-cv format to be able to show it.\n",
    "\n",
    "    opencvimage = np.array(pil_image)\n",
    "    return opencvimage\n",
    "\n",
    "# GUI 설계\n",
    "win = Tk() # 인스턴스 생성\n",
    "\n",
    "win.title(\"신원등록 시스템\") # 제목 표시줄 추가\n",
    "win.option_add(\"*Font\", \"맑은고딕 25\") # 전체 폰트\n",
    "\n",
    "# 라벨 추가\n",
    "lbl = Label(win, text=\"신원등록 시스템\")\n",
    "lbl.grid(row=0, column=0, columnspan = 3) # 라벨 행, 열 배치\n",
    "\n",
    "# 프레임 추가\n",
    "frm = Frame(win, bg=\"white\", width=720, height=480) # 프레임 너비, 높이 설정\n",
    "frm.grid(row=1, column=0, columnspan = 3) # 격자 행, 열 배치\n",
    "\n",
    "# 프레임 추가\n",
    "frm1 = Frame(win, width=700, height=75) # 프레임 너비, 높이 설정\n",
    "frm1.grid(row=3, column=0, columnspan = 3) # 격자 행, 열 배치\n",
    "\n",
    "# 라벨 추가\n",
    "lbl1 = Label(frm)\n",
    "lbl1.grid()\n",
    "\n",
    "cap = cv2.VideoCapture(0) # VideoCapture 객체 정의\n",
    "\n",
    "def video_play():\n",
    "   ret, frame = cap.read()\n",
    "   frame = cv2.flip(frame, 1) # 상하반전\n",
    "   frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "   img = Image.fromarray(frame)\n",
    "   imgtk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "   lbl1.imgtk = imgtk\n",
    "   lbl1.configure(image=imgtk)\n",
    "   lbl1.after(10, video_play)\n",
    "\n",
    "video_play()\n",
    "\n",
    "# 입력창 생성\n",
    "ent = Entry(win)\n",
    "ent.grid(row=2, column=0, columnspan = 3)\n",
    "ent.insert(0,\" 이름을 입력해주세요.. \") # 입력창 문자열 삽입\n",
    "\n",
    "def clear(event):\n",
    "    ent.delete(0, len(ent.get()))\n",
    "\n",
    "ent.bind(\"<Button-1>\", clear) # 입력창 클릭시 명령 (Button-1 = 좌클릭)\n",
    "\n",
    "# 버튼 추가\n",
    "btn = Button(win, text = \"신원등록\") # 버튼 생성\n",
    "btn.grid(row=3, column=0) # 라벨 행, 열 배치\n",
    "btn.config(width = 7, height = 1) # 버튼 크기\n",
    "\n",
    "# 버튼 추가\n",
    "btn1 = Button(win, text = \"촬영\") # 버튼 생성\n",
    "btn1.grid(row=3, column=1) # 라벨 행, 열 배치\n",
    "btn1.config(width = 7, height = 1) # 버튼 크기\n",
    "\n",
    "def alert():\n",
    "\n",
    "   a = ent.get()\n",
    "\n",
    "   parent_dir = \"train\"\n",
    "\n",
    "   path = os.path.join(parent_dir, a)\n",
    "\n",
    "   os.makedirs(path)\n",
    "    \n",
    "def alert1():\n",
    "\n",
    "   a = ent.get()\n",
    "\n",
    "   parent_dir = \"train\"\n",
    "\n",
    "   path = os.path.join(parent_dir, a)\n",
    "    \n",
    "   ret, frame = cap.read()\n",
    "   frame = cv2.flip(frame, 1) # Flip camera vertically\n",
    "   \n",
    "   # 컬러 이미지 저장\n",
    "   vein_img = path+ '\\picture_'+ datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.jpg'\n",
    "   cv2.imwrite(vein_img, frame)\n",
    "\n",
    "\n",
    "btn.config(command = alert) # 버튼 기능\n",
    "btn1.config(command = alert1) # 버튼 기능\n",
    "\n",
    "#################\n",
    "\n",
    "# 버튼 추가\n",
    "btn2 = Button(win, text = \"신원확인\") # 버튼 생성\n",
    "btn2.grid(row=3, column=2) # 라벨 행, 열 배치\n",
    "btn2.config(width = 7, height = 1) # 버튼 크기\n",
    "\n",
    "def alert2():\n",
    "\n",
    "    print(\"Training KNN classifier...\")\n",
    "    classifier = train(\"train\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "    print(\"Training complete!\")\n",
    "    # process one frame in every 30 frames for speed\n",
    "    process_this_frame = 29\n",
    "    print('Setting cameras up...')\n",
    "    # multiple cameras can be used with the format url = 'http://username:password@camera_ip:port'\n",
    "    #url = 'http://admin:admin@192.168.0.106:8081/'\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while 1 > 0:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Different resizing options can be chosen based on desired program runtime.\n",
    "            # Image resizing for more stable streaming\n",
    "            img = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "            process_this_frame = process_this_frame + 1\n",
    "            if process_this_frame % 30 == 0:\n",
    "                predictions = predict(img, model_path=\"trained_knn_model.clf\")\n",
    "            frame = show_prediction_labels_on_image(frame, predictions)\n",
    "            cv2.imshow('camera', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            \n",
    "            if key & 0xFF == ord('q') or key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "btn2.config(command = alert2) # 버튼 기능\n",
    "\n",
    "win.mainloop() #GUI 시작"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
